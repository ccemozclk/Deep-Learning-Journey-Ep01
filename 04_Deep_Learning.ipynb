{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Hm-_c89O7AWK"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load and Prepare Data\n",
        "# The CIFAR10 dataset is a color and mixed dataset.\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "QgfUXrQv7agI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a04e307-48a2-45a5-8535-413ed8657c3d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compress pixels between 0-1 (Normalize)\n",
        "train_images, test_images = train_images / 255.0, test_images / 255.0"
      ],
      "metadata": {
        "id": "eZge0OQq7py5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Model :"
      ],
      "metadata": {
        "id": "SY4v86JfMrpb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. We are establishing the CNN Model.\n",
        "model = models.Sequential([\n",
        "\n",
        "    # --- INTRODUCTION LAYER ---\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # --- INTERMEDIATE LAYER (Going Deeper) ---\n",
        "    # In the first layer, we found simple lines. Now, let's INCREASE the number of filters to find shapes.\n",
        "    # Generally, the number of filters doubles as the layers progress (32 -> 64).\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # --- DECISION-MAKING LAYER (BRAIN) ---\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "\n",
        "    # QUESTION 3: Output Layer\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j46ZOXxbMt1I",
        "outputId": "6dc61df9-e546-4439-aacf-47dcfa56229e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile and Train the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "6bQcaga5M1M8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Since this dataset is challenging, let's iterate through it 10 times (epochs).\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3DCZSbMM3Ol",
        "outputId": "97401093-3693-4bcf-8eb4-ee8ee2f67d4e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 49ms/step - accuracy: 0.3867 - loss: 1.6866 - val_accuracy: 0.5495 - val_loss: 1.2780\n",
            "Epoch 2/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 52ms/step - accuracy: 0.5886 - loss: 1.1661 - val_accuracy: 0.6161 - val_loss: 1.1081\n",
            "Epoch 3/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.6550 - loss: 0.9977 - val_accuracy: 0.6539 - val_loss: 0.9917\n",
            "Epoch 4/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 48ms/step - accuracy: 0.6822 - loss: 0.9086 - val_accuracy: 0.6724 - val_loss: 0.9456\n",
            "Epoch 5/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 47ms/step - accuracy: 0.7149 - loss: 0.8185 - val_accuracy: 0.6942 - val_loss: 0.9089\n",
            "Epoch 6/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 47ms/step - accuracy: 0.7348 - loss: 0.7608 - val_accuracy: 0.6918 - val_loss: 0.9310\n",
            "Epoch 7/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m90s\u001b[0m 52ms/step - accuracy: 0.7535 - loss: 0.7052 - val_accuracy: 0.6939 - val_loss: 0.9212\n",
            "Epoch 8/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 51ms/step - accuracy: 0.7650 - loss: 0.6625 - val_accuracy: 0.6958 - val_loss: 0.9220\n",
            "Epoch 9/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 48ms/step - accuracy: 0.7848 - loss: 0.6107 - val_accuracy: 0.6939 - val_loss: 0.9535\n",
            "Epoch 10/10\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 48ms/step - accuracy: 0.8003 - loss: 0.5769 - val_accuracy: 0.6927 - val_loss: 0.9664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmented Model :\n",
        "\n",
        "  - We apply Data Augmentation and Dropout (0.5) to prevent overfit."
      ],
      "metadata": {
        "id": "J5LT_uJuM31p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Class names (Necessary for reading results)\n",
        "class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n",
        "               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']"
      ],
      "metadata": {
        "id": "AU5neshIASx7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- WEAPON 1: DATA AUGMENTATION LAYER ---\n",
        "\n",
        "# This layer only works during training; it is disabled during testing.\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "  layers.RandomFlip(\"horizontal\"), # Flip the image horizontally\n",
        "  layers.RandomRotation(0.1),      # Rotate by 10%\n",
        "  layers.RandomZoom(0.1),          # Zoom in/out a little\n",
        "])"
      ],
      "metadata": {
        "id": "efWSlFmaEGpU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. We are installing the model (Improved Version)\n",
        "model = models.Sequential([\n",
        "\n",
        "    # Let's first distort/varietiate the images a bit.\n",
        "    data_augmentation,\n",
        "\n",
        "    # CNN Section (Eyes)\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "\n",
        "    # Classification Section (Brain)\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "\n",
        "    # --- WEAPON 2: DROPOUT ---\n",
        "    # Randomly shut down half (50%) of the neurons.\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "KHz06z757tmE"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the Model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "5knibEUK7-17"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Start Training (Let's do 15 laps this time because learning has become difficult!)\n",
        "print(\"The training is starting... (Please be patient, the Augmentation process is slow)\")\n",
        "history = model.fit(train_images, train_labels, epochs=15,\n",
        "                    validation_data=(test_images, test_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3p0sc7LES7a",
        "outputId": "ee07c771-f102-43b9-b0e1-ed31a8ef76e4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The training is starting... (Please be patient, the Augmentation process is slow)\n",
            "Epoch 1/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 63ms/step - accuracy: 0.2488 - loss: 2.0120 - val_accuracy: 0.4443 - val_loss: 1.5131\n",
            "Epoch 2/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m145s\u001b[0m 65ms/step - accuracy: 0.4286 - loss: 1.5814 - val_accuracy: 0.5114 - val_loss: 1.3190\n",
            "Epoch 3/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 64ms/step - accuracy: 0.4906 - loss: 1.4428 - val_accuracy: 0.5463 - val_loss: 1.2516\n",
            "Epoch 4/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 63ms/step - accuracy: 0.5099 - loss: 1.3877 - val_accuracy: 0.5710 - val_loss: 1.1997\n",
            "Epoch 5/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 62ms/step - accuracy: 0.5266 - loss: 1.3378 - val_accuracy: 0.5956 - val_loss: 1.1454\n",
            "Epoch 6/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 63ms/step - accuracy: 0.5406 - loss: 1.3062 - val_accuracy: 0.5637 - val_loss: 1.2395\n",
            "Epoch 7/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 62ms/step - accuracy: 0.5500 - loss: 1.2787 - val_accuracy: 0.6085 - val_loss: 1.1168\n",
            "Epoch 8/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 63ms/step - accuracy: 0.5657 - loss: 1.2423 - val_accuracy: 0.6262 - val_loss: 1.0624\n",
            "Epoch 9/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 63ms/step - accuracy: 0.5753 - loss: 1.2297 - val_accuracy: 0.6278 - val_loss: 1.0567\n",
            "Epoch 10/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m97s\u001b[0m 62ms/step - accuracy: 0.5805 - loss: 1.1945 - val_accuracy: 0.6293 - val_loss: 1.0617\n",
            "Epoch 11/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 62ms/step - accuracy: 0.5843 - loss: 1.1852 - val_accuracy: 0.6222 - val_loss: 1.0749\n",
            "Epoch 12/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 66ms/step - accuracy: 0.5955 - loss: 1.1694 - val_accuracy: 0.6140 - val_loss: 1.1267\n",
            "Epoch 13/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 63ms/step - accuracy: 0.6010 - loss: 1.1478 - val_accuracy: 0.6483 - val_loss: 0.9885\n",
            "Epoch 14/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - accuracy: 0.6044 - loss: 1.1404 - val_accuracy: 0.6511 - val_loss: 0.9927\n",
            "Epoch 15/15\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 62ms/step - accuracy: 0.6103 - loss: 1.1237 - val_accuracy: 0.6462 - val_loss: 1.0137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Testing !!"
      ],
      "metadata": {
        "id": "HZzyUZqIOV5w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TEST TIME ---\n",
        "import numpy as np\n",
        "# 1. Let's choose a random image from the test set.\n",
        "random_number = np.random.randint(0, 1000)\n",
        "choosed_image = test_images[random_number]\n",
        "real_tag = test_labels[random_number][0]\n",
        "\n",
        "# 2. Let's give it to the official model (We need to make its dimensions (1, 32, 32, 3) because the batch is waiting)\n",
        "img_for_prediction = np.expand_dims(choosed_image, 0)\n",
        "predictions = model.predict(img_for_prediction)\n",
        "\n",
        "# 3. Let's read the result.\n",
        "predicted_indeks = np.argmax(predictions)\n",
        "predicted_name = class_names[predicted_indeks]\n",
        "real_name = class_names[real_tag]\n",
        "confidence_rate = 100 * np.max(predictions)\n",
        "\n",
        "# 4. Let's print the result to the screen.\n",
        "plt.figure(figsize=(2,2))\n",
        "plt.imshow(choosed_image)\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Real One: {real_name}\")\n",
        "print(f\"AI Prediction: {predicted_name}\")\n",
        "print(f\"Confidence Rate: %{confidence_rate:.2f}\")\n",
        "\n",
        "if real_name == predicted_name:\n",
        "    print(\"Result: ✅ Succeed!\")\n",
        "else:\n",
        "    print(\"Result: ❌ Fail!\")"
      ],
      "metadata": {
        "id": "RUNwRchjLg53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "fa9c7e9a-a3f9-413a-c97f-910cb16ee9a7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 200x200 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Real One: Cat\n",
            "AI Prediction: Cat\n",
            "Confidence Rate: %58.85\n",
            "Result: ✅ Succeed!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Twv7vLkWnt1y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}